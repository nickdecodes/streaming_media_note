# H264编码详解

## 简介

[百度百科](https://baike.baidu.com/item/H.264/1022230?fromtitle=H264&fromid=7338504&fr=aladdin)

H.264是[国际标准化组织](https://baike.baidu.com/item/国际标准化组织)（[ISO](https://baike.baidu.com/item/ISO)）和[国际电信联盟](https://baike.baidu.com/item/国际电信联盟/502493)（ITU）共同提出的继MPEG4之后的[新一代](https://baike.baidu.com/item/新一代)数字视频[压缩格式](https://baike.baidu.com/item/压缩格式)。H.264是ITU-T以H.26x系列为名称命名的[视频编解码技术](https://baike.baidu.com/item/视频编解码技术)标准之一。H.264是ITU-T的VCEG（视频编码专家组）和ISO/IEC的MPEG（活动图像编码专家组）的联合视频组（JVT：joint video team）开发的一个数字视频编码标准。该标准最早来自于ITU-T的称之为H.26L的项目的开发。H.26L这个名称虽然不太常见，但是一直被使用着。H.264是ITU-T以H.26x系列为名称命名的标准之一，AVC是ISO/IEC MPEG一方的称呼。

##   编码器

### 三种帧的说明

- I 帧：帧内编码帧，帧表示关键帧，你可以理解为这一帧画面的完整保留；解码时只需要本帧数据就可以完成（因为包含完整画面）


> **I 帧的特点：**
>
> - a. 它是一个全帧压缩编码帧，它将全帧图像信息进行JPEG压缩编码及传输
>
> - b. 解码时仅用I 帧的数据就可重构完整图像
>
> - c. I 帧描述了图像背景和运动主体的详情
>
> - d. I 帧不需要参考其他画面而生成
>
> - e. I 帧是P帧和B帧的参考帧（其质量直接影响到同组中以后各帧的质量）
>
> - f. I 帧不需要考虑运动矢量
>
> - g. I 帧所占数据的信息量比较大
>

- **P帧**：前向预测编码帧。P帧表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧的画面差别的数据）

- **P帧的预测与重构**：P帧是以 I 帧为参考帧，在 I 帧中找出P帧“某点”的预测值和运动矢量，取预测差值和运动矢量一起传送。在接收端根据运行矢量从 I 帧找出P帧“某点”的预测值并与差值相加以得到P帧“某点”样值，从而可得到完整的P帧。

> **P帧的特点：**
>
> - a. P帧是 I 帧后面相隔1~2帧的编码帧
>
> - b. P帧采用运动补偿的方法传送它与前面的I或P帧的差值及运动矢量（预测误差）
>
> - c. 解码时必须将帧中的预测值与预测误差求和后才能重构完整的P帧图像
>
> - d. P帧属于前向预测的帧间编码。它只参考前面最靠近它的 I 帧或P帧
>
> - e. 由于P帧是参考帧，它可能造成解码错误的扩散
>
> - f. 由于是差值传送，P帧的压缩比较高
>

- **B帧**：双向预测内插编码帧。B帧是双向差别帧，也就是B帧记录的是本帧与前后帧的差别（具体比较复杂，有4种情况，但我这样说简单些），换言之，要解码B帧。不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累。

- **B帧的预测与重构**:  B帧以前面的 I 或P帧和后面的P帧为参考帧，“找出”B帧“某点”的预测值和两个运动矢量，并取预测差值和运动矢量传送。接收端根据运动矢量在两个参考帧中“找出（算出）”预测值并与差值求和，得到B帧“某点”样值，从而可得到完整的B帧。

> **B帧的特点：**
>
> - a. B帧是由前面的 I 或P帧和后面的P帧进行预测的
>
> - b. B帧传送的是它与前面的 I 或P帧和后面的P帧之间的预测误差及运动矢量
>
> - c. B帧是双向预测编码帧
>
> - d. B帧压缩比最高，因为它只反映并参考帧间运动主体的变化情况，预测比较准确
>
> - e. B帧不是参考帧，不会造成解码错误的扩散
>

```
注：I、B、P帧是根据压缩算法的需要，是人为定义的，他们都是实实在在的物理帧。
一般来说，帧的压缩率是7（跟JPG差不多），
P帧是20，B帧可以达到50.可见使用B帧能节省大量空间，
节省出来的空间可以用来保存多一些帧，这样在相同码率下，可以提供更好的画质。
```



### 压缩算法的说明

**h264的压缩方法**：

- 1、分组：把几帧图像分为一组（GOP，也就是一个序列），为防止运动变化，帧数不宜取多
- 2、定义帧：将每组内各帧图像定义为三种类型，即 I 帧、B帧和P帧

- 3、预测帧：以帧作为基础帧，以帧预测P帧，再由 I 帧和P帧预测B帧

- 4、数据传输：最后将 I  帧数据与预测的差值信息进行存储和传输

**帧内**（Intraframe）压缩也称为空间压缩（Spatial compression）。当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息，这实际上与静态图像压缩类似。帧内一般采用有损压缩算法，由于帧内压缩是编码一个完整的图像，因此可以独立的解码、显示。帧内压缩一般达不到很高的压缩，跟编码jpeg差不多。

**帧间**（Interframe）压缩的原理是：相邻几帧的数据有很大的相关性，或者说前后两帧信息变化很小的特点，也即连续的视频及其相邻帧之间具有冗余信息，根据这一特性，压缩相邻帧之间的冗余量就可以进一步提高压缩量，减少压缩比。帧间压缩也称为时间压缩，它通过比较时间轴上不同帧之间的数据进行压缩。帧间压缩一般是无损的。帧差值（Frame differencing）算法是一种典型的时间压缩发，它通过比较本帧与相邻帧之间的差异，仅记录本帧与其相邻帧的差值，这样可以大大减少数据量。

**顺便说下有损**（Lossy）压缩和无损（Lossy less）压缩。无损压缩也即压缩前和解压缩后的数据完全一致。多数的无损压缩都采用RLE行程编码算法。有损压缩意味着解压缩后的数据与压缩前的数据不一致。在压缩的过程中要丢失一些人眼和耳朵所不敏感的图像或音频信息，而且丢失的信息不可恢复。几乎所有高压缩的算法都采用有损压缩，这样才能达到低数据率的目标。丢失的数据率与压缩比有关，压缩比越小，丢失的数据越多，解压缩后的效果一般越差。此外，某些有损压缩算法采用多次重复压缩的方式，这样还会引起额外的数据丢失。



### 手写H264编码器

要彻底理解视频编码原理，看书都是虚的，需要实际动手，实现一个简单的视频编码器：

知识准备：基本图像处理知识，信号的时域和频域问题，熟练掌握傅立叶正反变换，一维、二维傅立叶变换，以及其变种，dct变换，快速dct变换。 

#### 第一步：实现有损图像压缩和解压

参考JPEG原理，将RGB->YUV，然后Y/U/V看成三张不同的图片，将其中一张图片分为8x8的block进行dct变换（可以直接进行二维dct变换，或者按一定顺序将8x8的二维数组整理成一个64字节的一维数组），还是得到一个8x8的整数频率数据。于是表示图像大轮廓的低频信号（人眼敏感的信号）集中在8x8的左上角；表示图像细节的高频信号集中在右下角。

接着将其量化，所谓**量化**，就是信号采样的步长，8x8的整数频率数据块，每个数据都要除以对应位置的步长，左上角相对重要的低频信号步长是1，也就是说0-255，是多少就是多少。而右下角是不太重要的高频信号，比如步长取10，那么这些位置的数据都要/10，实际解码的时候再将他们*10恢复出来，这样经过编码的时候/10和解码的时候*10，那么步长为10的信号1, 13, 25, 37就会变成规矩的：0, 10, 20, 30, 对小于步长10的部分我们直接丢弃了，因为高频不太重要。 

**经过量化以后**，8x8的数据块左上角的数据由于步长小，都是比较离散的，而靠近右下角的高频数据，都比较统一，或者是一串0，因此图像大量的细节被我们丢弃了，这时候，我们用无损压缩方式，比如lzma2算法（jpeg是rle + huffman）将这64个byte压缩起来，由于后面高频数据步长大，做了除法以后，这些值都比较小，而且比较靠近，甚至右下部分都是一串0，十分便于压缩。

JPEG图像有个问题就是低码率时 block边界比较严重，现代图片压缩技术往往要配合一些de-block算法，比如最简单的就是边界部分几个像素点和周围插值模糊一下。 

>  做到这里我们实现了一个同 jpeg类似的静态图片有损压缩算法。在视频里面用来保存I帧数据。 	 

#### 第二步：实现宏块误差计算

**视频**由连续的若干图像帧组成，分为 I帧，P帧，所谓I帧，就是不依赖就可以独立解码的视频图像帧，而P帧则需要依赖前面已解码的视频帧，配合一定数据才能生成出来。所以视频中I帧往往都比较大，而P帧比较小，如果播放器一开始收到了P帧那么是无法播放的，只有收到下一个I帧才能开始播放。I帧多了视频就变大，I帧少了，数据量是小了，但视频受到丢包或者数据错误的影响却又会更严重。

那么所谓运动预测编码，其实就是P帧的生成过程：继续将图片分成 16x16的block（为了简单只讨论yuv的y分量压缩）。I帧内部单帧图片压缩我们采用了8x8的block，而这里用16x16的block来提高帧间编码压缩率（当然也会有更多细节损失），我们用 x, y表示像素点坐标，而s,t表示block坐标，那么坐标为（x,y）的像素点所属的block坐标为： 

```c
s = x / 16 = x >> 4
t = y / 16 = y >> 4
```

接着要计算两个**block的相似度**，即矢量的距离，可以表示为一个256维矢量（16x16）像素点色彩距离的平方，我们先定义两个颜色的误差为： 

```text
PixelDiff(c1, c2) = (c1- c2) ^ 2
```

**那么256个点的误差**可以表示为所有对应点的像素误差和：

```text
BlockDiff(b1, b2) = sum( PixelDiff(c1, c2) for c1 in b1 for c2 in b2)
```


代码化为：

```c
int block_diff(const unsigned char b1[16][16], const unsigned char b2[16][16]) {
    int sum = 0;
    for (int i = 0; i < 16; i++) {
         for (int j = 0; j < 16; j++) {
              int c1 = b1[i][j];
              int c2 = b2[i][j];
              sum += (c1 - c2) * (c1 - c2);
         }
    }
    return sum;
}
```


有了这个block求差的函数，我们就可以针对**特定block**，搜索另外若**干个block**中哪个和它最相似了（误差最小）。

#### 第三步：实现运动预测编码

根据上面的宏块比较函数，你已经可以知道两个block到底像不像了，越象的block，block_diff返回值越低。那么我们有两帧相邻的图片，P1，P2，假设 P1已经完成编码了，现在要对 P2进行P帧编码，其实就是轮询 P2里面的每一个 block，为P2中每一个block找出上一帧中相似度最高的block坐标，并记录下来，具体伪代码可以表示为：

```c
unsigned char block[16][16];
for (int t = 0; t <= maxt; t++) {
    for (int s = 0; s <= maxs; s++) {
         picture_get_block(P2, s * 16, t * 16, block); // 取得图片 P2 的 block
         int x, y;
         block_search_nearest(P1, &x, &y, block); // 在P1中搜索最相似的block
         output(x, y);  // 将P1中最相似的block的左上角像素坐标 (x, y) 输出
    }
}
```


其中在P1中搜索最相似 block的 block_search_nearest 函数原理是比较简单的，我们可以暴力点用两个for循环轮询 P1中每个像素点开始的16x16的block（速度较慢），当然实际中不可能这么暴力搜索，而是围绕P2中该block对应坐标在P1中位置作为中心，慢慢四周扩散，搜索一定步长，并得到一个 ：**按照一定顺序进行搜索，并且在一定范围内最相似的宏块坐标**。 。

> 于是P2进行运动预测编码的结果就是一大堆(x,y)的坐标，代表P2上每个block在上一帧P1里面最相似的 block的位置。反过来说可能更容易理解，我们可以把第三步整个过程定义为： 

怎么用若干 P1里不同起始位置的block拼凑出图片P2来，使得拼凑以后的结果和P2最像。

#### 第四步：实现P帧编码

拼凑的结果就是一系列(x,y)的坐标数据，我们继续用lzma2将它们先压缩起来，按照 vcd的分辨率

352 x 240，我们横向需要 352 / 16 = 22个block，纵向需要 240 / 16 = 15 个block，可以用 P1中 22 x 15 = 330 

个 block的坐标信息生成一张和P2很类似的图片 P2' ： 

```c
for (int t = 0; t < 15; t++) {
    for (int s = 0; s < 22; s++, next++) {
         int x = block_positions[next].x;   // 取得对应 P1上的 block像素位置 x
         int y = block_positions[next].y;   // 取得对应 P1上的 block像素位置 y
         // 将 P1位置(x,y)开始的 16 x 16 的图块拷贝到 P2'的 (s * 16, t * 16)处
         CopyRect(P2', s * 16, t * 16, P1, x, y, 16, 16); 
    }
}
```

我们把用来生成P2的P1称为 P2的 “参考帧”，再把刚才那一堆P1内用来拼成P2的 block坐标称为 “**运动矢量**”，这是P帧里面最主要的数据内容。但是此时由P1和这些坐标数据拼凑出来的P2，你会发现粗看和P2很象，但细看会发现有些支离破碎，并且边缘比较明显，怎么办呢？我们需要第四步。


####  第五步：实现P帧编码

有了刚才的运动预测矢量（一堆block的坐标），我们先用P1按照这些数据拼凑出一张类似 P2的新图片叫做P2'，然后同P2上每个像素做减法，得到一张保存 differ的图片： 

```c
D2 = (P2 - P2') / 2
```

误差图片 D2上每一个点等于 P2上对应位置的点的颜色减去 P2'上对应位置的点的颜色再除以2，用8位表示差值，值是循环的，比如-2就是255，这里一般可以在结果上 + 0x80，即 128代表0，129代表2，127代表-2。继续用一个 8位的整数可以表示 [-254, 254] 之间的误差范围，步长精度是2。 

按照第三步实现的逻辑，P2'其实已经很像P2了，只是有些误差，我们将这些误差保存成了图片D2，所以图片D2中，信息量其实已经很小了，都是些细节修善，比起直接保存一张完整图片熵要低很多的。所以我们将 D2用类似第一步提到的有损图片压缩方法进行编码，得到最终的P帧数据：

```text
Encode(P2) = Lzma2(block_positions) + 有损图像编码（D2）
```


具体在操作的时候，D2的图像块可以用16x16进行有损编码，因为前面的运动预测数据是按16x16的宏块搜索的，而不用象I帧那样精确的用8x8表示，同时保存误差图时，量化的精度可以更粗一些用不着象I帧那么精确，可以理解成用质量更低的JPEG编码，按照16x16的块进行编码，加上误差图D2本来信息量就不高，这样的保存方式能够节省不少空间。	

####  第六步：实现GOP生成

通过前面的代码，我们实现了I帧编码和P帧编码，P帧是参考P1对P2进行编码，而所谓B帧，就是参考 P1和 P3对P2进行编码，当然间隔不一定是1，比如可以是参考P1和P5对P2进行编码，前提条件是P5可以依赖P1及以前的数据进行解码。

不过对于一个完整的简版视频编码器，I帧和P帧编码已经够了，市面上任然有很多面向低延迟的商用编码器是直接干掉B帧的，因为做实时传输时收到B帧没法播放，之后再往后好几帧收到下一个I或者P帧时，先前收到的B帧才能被解码出来，造成不少的延迟。 

而所谓的 GOP (Group of picture) 就是由一系列类似 I, P, B, B, P, B, B, P, B, B P 组成的一个可以完整被解码出来的图像组，而所谓视频文件，就是一个接一个的GOP，每个GOP由一个I帧开头，然后接下来一组连续的P 或者 B构成，播放时只有完整收到下一个GOP的I帧才能开始播放。

最后是关于参考帧选择，前面提到的 P2生成过程是参考了 P1，假设一个GOP中十张图片，是 I1, P1, P2, P3, P4, ... P9 保存的，如果P1参考I1，P2参考P1, P3参考P2 .... P9参考P8这样每一个P帧都是参考上一帧进行编码的话，误差容易越来越大，因为P1已经引入一定误差了，P2在P1的基础上误差更大，到了P9的话，图片质量可能已经没法看了。 

因此正确的参考帧选择往往不需要这样死板，比如可以P1-P9全部参考I1来生成，或者，P1-P4参考I1来生成，而P5-P9则参考P5来生成，这样步子小点，误差也不算太离谱。

####  第七步：容器组装

我们生成了一组组编码过的GOP了，这时候需要一定的文件格式将他们恰当的保存下来，记录视频信息，比如分辨率，帧率，时间索引等，就是一个类似MP4（h.264的容器）文件的东西。至此一个简单的小型编码器我们已经完成了，可以用 SDL / DirectX / OpenGL 配合实现一个播放器，愉快的将自己编码器编码的视频播放出来。

#### 第八步：优化改进

这时候你已经大概学习并掌握了视频编码的基础原理了，接下来大量的优化改进的坑等着你去填呢。优化有两大方向，编码效率优化和编码性能优化：前者追求同质量（同信噪比）下更低的码率，后者追求同样质量和码率的情况下，更快的编码速度。

有这个基础后接下来可以回过头去看JPEG标准，MPEG1-2标准，并阅读相关实现代码，你会发现简单很多了，接着肯H.264代码，不用全部看可以针对性的了解以下H.264的I帧编码和各种搜索预测方法，有H.264的底子，你了解 HEVC和 vpx就比较容易了。 

参考这些编码器一些有意思的实现来改进自己的编码器，试验性质，可以侧重原理，各种优化技巧了解下即可，本来就是hack性质的。

>  有卯用呢？首先肯定很好玩，其次，当你有需要使用并修改这些编码器为他们增加新特性的时候，你会发现前面的知识很管用了。 

------有朋友说光有代码没有图片演示看不大明白，好我们补充一下图片演示：

#### 画面演示

这是第一帧画面：P1（我们的参考帧） 

![04-56](./pic/04-56.png)

 这是第二帧画面：P2（需要编码的帧） 

![04-57](./pic/04-57.png)

> 从视频中截取的两张间隔1-2秒的画面，和实际情况类似，下面我们进行几次运动搜索：

这是一个**演示程序**，鼠标选中P2上任意16x16的Block，即可搜索出P1上的 BestMatch 宏块。虽然车辆在运动，从远到近，但是依然找到了最接近的**宏块坐标**。

搜索演示2：空中电线交叉位置（上图P1，下图P2） 

![04-58](./pic/04-58.png)

搜索演示3：报刊停的广告海报 

![04-59](./pic/04-59.png)

> 同样顺利在P1中找到最接近P2里海报的宏块位置。

 图片全搜索：根据P1和运动矢量数据（在P2中搜索到每一个宏块在P1中最相似的位置集合）还原出来的P2'，即完全用P1各个位置的宏块拼凑出来最像P2的图片P2'，效果如下： 

![04-60](./pic/04-60.png)

仔细观察，有些支离破碎对吧？肯定啊，拼凑出来的东西就是这样，现在我们用P2`和P2像素相减，得到差分图 D2 = (P2' - P2) / 2 + 0x80：

![04-61](./pic/04-61.png)

嗯，这就是P2`和P2两幅图片的不同处，看到没？基本只有低频了！高频数据少到我们可以忽略，这时用有损压缩方式比较差的效果来保存误差图D2，只要5KB的大小。
接着我们根据运动矢量还原的 P2'及差分图D2来还原新的 P2，NewP2 = P2' + (D2 - 0x80) * 2：

![04-62](./pic/04-62.png)

> 这就是之前支离破碎的 P2` 加上误差 D2之后变成了清晰可见的样子，基本还原了原图P2。
> ​由于D2仅仅占5KB，加上压缩过后的运动矢量不过7KB，

​		**所以参考P1我们只需要额外 7KB的数据量就可以完整表示P2了，而如果独立将P2用质量尚可的有损压缩方式独立压缩，则至少要去到50-60KB，这一下节省了差不多8倍的空间，正就是所谓运动编码的基本原理。**

再者误差我们保存的是（P2-P2’）/2 + 0x80，实际使用时我们会用更有效率的方式，比如让[-64,64]之间的色差精度为1，[-255,-64], [64, 255] 之间的色差精度为2-3，这样会更加真实一些。

现代视频编码中，除了帧间预测，I帧还使用了大量帧内预测，而不是完全dct量化后编码，前面帧间预测我们使用了参考帧的宏块移动拼凑新帧的方式进行，而所谓帧内预测就是同一幅画面中，未编码部分使用已编码部分拼凑而成。。。。。。。

H264是新一代的编码标准，以高压缩高质量和支持多种网络的流媒体传输著称在编码方面，



### 解码器

H.264的目标应用涵盖了目前大部分的视频服务，如有线电视远程监控、交互媒体、数字电视、视频会议、视频点播、流媒体服务等。H.264为解决不同应用中的网络传输的差异。定义了两层：

视频编码层（VCL：Video Coding Layer）负责高效的视频内容表示，

网络提取层（NAL：Network Abstraction Layer）负责以网络所要求的恰当的方式对数据进行打包和传送。

如图所示。

![](./pic/04-95.png)

基本层次（Baseline Profile）：该层次使用了H.264的除了B-Slices，CABAC以及交织编码模式外所有的特性。该层次主要使用于低时延的实时应用场合。

主要层次（Main Profile）：包含Baseline profile的所有特性，并包括了B-slices，CABAC以及交织编码模式。它主要针对对时延要求不高，当压缩率和质量要求较高的场合。

扩展层次(Profile X)：支持所有Baseline profile的特性，但不支持CABAC以及基于宏块的自适应帧场编码。该层次主要针对的时各种网络视频流传输方面的应用。



**CABAC**

**DCT变换**

**多种运动补偿块**

有7种形状的运动补偿可供选用，这7种块是：INTER16x16，INTER16x8，INTER8x16，INTER8x8，INTER8x4，INTER4x8，INTER4x4。根据运动补偿采用的块尺寸的不同，宏块的编码模式分为四种，前三种模式分别按照一个16x16块、两个16x8块和两个8x16块来进行运动补偿；最后一种模式记作P8x8，在P8x8模式下，一个宏块被分为4个8x8的子块，而每一个子块又有4种可能的子模式，分别按照一个8x8块、两个8x4块、两个4x8块及四个4x4块进行运动补偿，如图3.19所示，第一行是宏块四种模式，第二行是子块四种模式。

![](./pic/04-96.png)

块大小的选择是否合理对于压缩效果的好坏有很大的影响，通常来说，对于变化缓慢的部分采用较大分块效果比较好，对于包含较多细节的部分则应该采用较小的分块方式。

1/4像素精度运动估计

帧内编码宏块的每一分块都是由参考帧中相同大小的区域预测得到。这两个区域之间的偏移量即运动矢量。由于图像的运动不可能总是整像素的。因此引入了亚像素运动矢量。对亮度分量，运动矢量的分辨率为1/4像素。由于参考帧中本身不可能存在亚像素采样点，因此需要利用其临近像素内插产生亚像素采样点。亚像素采样点的内插产生过程，如图所示

![](./pic/04-97.png)

半像素内插值分别由运动于水平和垂直方向的一维6阶滤波器产生。1/4像素值由整数像素和半像素点求均值取得。
例如：

```
b=round（（E-5F+20G+20H-5I+J）/32） a=round（（G+b）/2） e=round（（b+h）/2）
```

由于亮度分量中的1/4像素精度运动矢量将在色度分量中产生1/8像素精度。因此，采用线性内插法产生1/8像素采样点。

```
a=round（（[（8-dx）.（8-dy）A+dx.（8-dy）B+（8-dx）.dyC+dx.dyD]/64）
```



**图片分割**

H.264支持slice结构的图片分割。一个slice有一帧图片内的若干宏块组成。编码器端对slice种包含的宏块数目没有限制。一个slice可以仅包含一个宏块也可以包含该帧中的所有宏块。然而，任何一个宏块都只能包含在某一个slice中，不允许重复出现（在冗余slice方法中例外)。

采用slice结构的主要动机是使编码的slice大小能适应不同的MTU大小。当它同时能应用于交叉打包等方法的实现方案中。

**多参考帧选择**

多参考帧选择在之前的一些视频编码标准中也可以得到应用。该方法尤其使用于具有反馈机制的系统中。但在时延要求较高的应用中意义不大。与以往标准的P帧、B帧不同，H.264采用了前向与后向多个参考帧的预测

**数据分块**

通常，宏块中素有的码元都是被编码在单一的比特串中的。数据分块则为每一个slice创建多个比特串。
在H.264中，使用了三种不同类型的数据分块。

头信息块，包括宏块类型，量化参数，运动矢量。这些信息是最重要的，因为离开他们，被的数据块种的码元都无法使用。该数据分块称为A类数据分块。

帧内编码信息数据块，称为B类数据分块。它包含帧内编码宏块类型，帧内编码系数。对应的slice来说，B类数据分块的可用性依赖于A类数据分块。和帧间编码信息数据块不通的是，帧内编码信息能防止进一步的偏差，因此比帧间编码信息更重要。

帧间编码信息数据块，称为C类数据分块。它包含帧间编码宏块类型，帧间编码系数。它通常是slice种最大的一部分。帧间编码信息数据块是不重要的一部分。它所包含的信息并不提供编解码器之间的同步。C类数据分块的可用性也依赖于A类数据分块，但于B类数据分块无关。

当采用数据分块方式的时候，源编码器将不通类型的码元放到三个不同的比特缓冲器种此外，slice大小也需要调整，以使最大数据分块不会大于最大的MTU尺寸。以此，对数据分块进行操作的是源编码器而不是NAL。
在解码器端，在开始正确解码之前必须获得所有数据分块信息。然而，如果帧间或帧内编码数据块信息丢失了，头信息仍然能够有效地应用于提高差错恢复效率。头信息种包含宏块类型，用动矢量等信息，因此能够据此较高质量地复制信息。而仅仅丢失了一些图像纹理信息。

**参数集**

序列参数集包括与一图片序列相关地所有信息。图像参数集包含与图像中所有slice相关地信息。在解码器端可以存储多个不同地序列和图片参数集。编码器可以选择适当地图片参数集，图片参数集本身又包含所引用地序列参数集信息。

参数集的创造性应用极大地提高了错误恢复性能。在容错环境中使用参数集地关键是确保参数集能可靠并及时地到达接受端解码器。一次可以用频带外可靠通讯控制协议传送参数集，并确保在解码器从实时通讯信道接收到第一个需要参考该参数集地slice数据之前送达。或者也可以在频带内传输，但必须采用一些应用层保护措施（例如传送一参数集地多个复制，以提高至少一个复制到底目的地地概率）。第三中方案是在编码器和解码器端预先放置一些参数集，编解码器都必须在其中选择参数集。

**可变宏块排序**

可变宏块排序（FMO，Flexible Macroblock Ordering）可以在Baseline和Ext4ended模式中使用，但不允许在Main模式重使用。可变宏块排序允许将宏块不按照扫描顺序分配给slice。具体地分配策略由一宏块分配映射图（MBAmap）规定。在slice内，宏块仍然按照正常地扫描顺序编码。

该特性提供了一种将一帧图像中的宏块分配到多个slice中的模式，每个slice都是一个独立的编码单位，无论是帧间还是帧内编码都不能越界，如果在传输过程中出现数据丢失的情况，可以利用已接收到的宏块数据来对丢失的宏块数据进行恢复。

![](./pic/04-98.png)



**slice**

slice是一个类似于H.263中图像组（GOP）的概念，一个slice是由一系列按光栅扫描顺序排列的宏块组成。一般情况下每个宏块均包含一个16×16 的亮度阵列，当视频格式不是单色时，还包含和两个相应的色度阵列。如果没有使用宏块自适应帧/场解码，每个宏块代表图像中的一个空间矩形区域。例如，如图3.22所示，一幅图像被分为两个条带。

![](./pic/04-99.png)

每个slice都是一个独立的编码单位，无论是帧间还是帧内编码都不能越界。冗余slice允许编码器在同一数据流中嵌入同一slice中宏块地一个或多个冗余表示。这种做法和传输层冗余技术，例如包复制等，关键区别是在冗余slice中宏块地冗余表示可以使用不同地编码参数编码。例如，首先要表示可以使用相对较低的量化系数以获得较低的图像质量，而在冗余表示中可以用相对较高的量化系数以减少比特数。当解码器正确接受到首要表示时，将冗余表示丢弃。而如果首要表示由于包丢失等原因无法正确获得，能够用冗余表示中地信息将相应slice数据恢复。冗余slice 最初是为支持高差错无线通信环境而引入的，但在基于IP的环境中同样有效。

**通过块匹配估计运动的方法**

完全抵消所有运动的运动补偿器将产生非常好的预测帧，以至于实际上在差别图片中不会存在任何功率。我们需要相对较多的数据以详细描述运动，但是只需要相对教少的数据，以描述差别帧。无可否认，甚至使用艺术技术也不可能从一般的帧源中识别和测量任何对象的运动。我们不得不满足于简化图片模型，例如经常使用的块匹配技术。除了次优的运动补偿之外，差别图片所需的数据速率比没有运动补偿所需的速率要小很多。进一步而言，我们的优势是特别简单，因而节省描述运动所需的位数。这在部分程度哂纳感弥补了差别图片的信号功率的不足，这种信号没有完全最小化。

**使用块匹配技术的运动估计器**

在数据压缩中，块匹配运动估计器可以任意处理每个新帧，使其用大小相同的直接相邻的对象进行传送。另外，对象仅仅能在2维平面上在一个方向上统一地移动。因而，被传输的帧被分割为一系列矩形图案块，它们是连续产生的。运动预测器假设图案块仅仅能在x和y方向上移动一个最大值。对于每个图案块，存在一个搜索区域，根据基本模型，在先前帧的这个区域内可以找到那个图案块。在使用等长步长的情况下，图案块逐渐移动通过搜索区域内的连续位置，并且每个位置都和旧图片进行比较。
位置变换也称为位移，如果某个位移达到了最佳的相似性或匹配结果，则它称为搜索后运动。然后，运动补偿帧的块将填充属于先前帧的块的内容，这将和前面搜索的图案块产生最佳的匹配。通过这种方式，运动补偿帧可以和瞬态帧尽可能地接近。

位移中的x和y成分通过侧向通道而传送到接受器，目的是可以从旧帧中构造运动补偿帧。对先前帧的内容执行这个操作，从而对已知图片进行这个操作，这就是这种编码技术的本质优点。

向量的数据速率取决于查找区域的带，从而取决于最大的位移，以及期望的向量的精确程度。对象的轮廓没有必要传送，原因是所有的对象具有相同的矩形。

**P图像的VLC编码**

VLC是可变长编码，VLC是统计编码技术，它的基本思想是：对出现频率较高的数值分配比特数较少的码字，而对出现频率较低的数值分配比特数较多的码字，因此从总的效果看，数据量比用均匀分配比特数的数据量要少。可变长编码是对Huffman编码的改进

P图像是参考过去的帧内图像或者过去预测得到得图像用运动补偿预测技术进行编码，P图像得编码也是以图像宏块为基本编码单元。预测编码得 基础是运动估值，它将直接影响到整个系统得编码效率和压缩性能，因此希望找到一种预测精度高同时计算量又小得运动估值算法。

正如I画面一样，每一幅P画面被分为一片或多片，每一片又被划分为若干宏块。对P画面的编码要比I画面复杂的多，因为要构造运动补偿宏块。运动补偿宏块与当前宏块的差值被一个二维的DCT变换为8x8的变换系数矩阵，这些系数在被量化成一组量化系数，最后，对量化后的系数采用行程长度技术编码。表3.11和3.12分别给出了P画面和B画面中所支持的宏块类型及VLC编码。

P画面中的宏块类型及VLC编码

| 宏块类型 | VLC码   | INTRA | MOTION FORWARD | CODED PATTERN | QUANT |
| -------- | ------- | ----- | -------------- | ------------- | ----- |
| pred_mc  | 1       | 0     | 1              | 1             | 0     |
| pred_c   | 01      | 0     | 0              | 1             | 0     |
| pred_m   | 001     | 0     | 1              | 0             | 0     |
| intra_d  | 0001 1  | 1     | 0              | 0             | 0     |
| pred_mcq | 0001 0  | 0     | 1              | 1             | 1     |
| pred_cq  | 0000 1  | 0     | 0              | 1             | 1     |
| intra_q  | 0000 01 | 1     | 0              | 0             | 1     |
| skipped  | 无      |       |                |               |       |

B画面中的宏块类型及VLC编码

| 宏块类型 | VLC码   | INTRA | MOTION FORWARD | MOTION BACKWARD | CODED PATTERN | QUANT |
| -------- | ------- | ----- | -------------- | --------------- | ------------- | ----- |
| pred_I   | 10      | 0     | 1              | 1               | 0             | 0     |
| pred_ic  | 11      | 0     | 1              | 1               | 1             | 0     |
| pred_b   | 010     | 0     | 0              | 1               | 0             | 0     |
| pred_bc  | 011     | 0     | 0              | 1               | 1             | 0     |
| pred_f   | 0010    | 0     | 1              | 0               | 0             | 0     |
| pred_fc  | 0011    | 0     | 1              | 0               | 1             | 0     |
| intra_d  | 0001 1  | 1     | 0              | 0               | 0             | 0     |
| pred_icq | 0001 0  | 0     | 1              | 1               | 0             | 1     |
| pred_fcq | 0000 11 | 0     | 1              | 0               | 0             | 1     |
| pred_bcq | 0000 10 | 1     | 0              | 1               | 1             | 1     |
| intra_q  | 0000 01 | 1     | 0              | 0               | 0             | 1     |
| skippde  | 无      |       |                |                 |               |       |

每一帧B画面被划分成一片或多片，每一片又被划分为若干宏块。由于要构造几种类型的运动补偿宏块：前向、后向、插播，所以对B画面的编码要比对P画面复杂的多。首先用一个二维DCT将运动补偿宏块与当前块之间的差值变换为8x8的变换系数矩阵，然后对着些系数进行量化，产生一组量化的系数，最后对这些量化后的系数用行程长度技术进行编码。

编码器不需要存储解码的B画面，因为B画面不用于运动补偿。

B画面宏块比P画面多了 几种类型，如果仅有前向运动矢量，则像P画面那样，从前面的一帧画面种构造运动补偿宏块。如果仅有后向运动矢量，则从后面的一帧画面种构造运动补偿宏块。如果既有前向也有后向运动矢量，则从前面以及后面的画面种构造运动补偿宏块，对结果求平均，用以形成插补宏块。

如同需要存储I画面一样，编码器也需要存储解了码的P画面，一位该P画面很可能会作为运动补偿的开始点。因此，编码器将要从量化系数种重构该画面的图像。
H.264所支持的帧编码模式如表所示。

| 帧类型           | 描述                                                        | 支持的框架 |
| ---------------- | ----------------------------------------------------------- | ---------- |
| I(Intra)         | 只包含帧内预测的宏块(I)                                     | 全部       |
| P(Predicted)     | 包含帧间预测宏块(P)和I型宏块                                | 全部       |
| B(Bi-Predictive) | 包含帧间双向预测宏块(B)和I型宏块                            | 扩展和主   |
| SP(Switching P)  | 利于在编码的比特流中切换,包括I和P宏块                       | 扩展       |
| SI(Switching I)  | 利于在编码的比特流中切换,包含SI宏块(一种特殊的帧内编码宏块) | 扩展       |
